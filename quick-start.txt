The guide is tested on 3 VMs cluster with Ubuntu 20.04 installed

*******************************************************************************************************************************************************************
Install Kubespray dependencies
*******************************************************************************************************************************************************************
1. Download this repo
2. sudo pip install -r requirements.txt

*******************************************************************************************************************************************************************
Configure your own inventory 
********************************************************************************************************************************************************************

Duplicate sample inventory - not to mess up with clean sample
==============================================================
cp -rfp inventory/sample inventory/mycluster

Configure all nodes IP would like to join the cluster - ensure all nodes are reachable via IP on each others
============================================================================================================
declare -a IPS=(192.168.0.17 192.168.0.18 192.168.0.19)
CONFIG_FILE=inventory/mycluster/hosts.yml python3 contrib/inventory_builder/inventory.py ${IPS[@]}

*You could change the configuration later by editing the inventory/mycluster/hosts.yml file

Change CNI plugin to calico
===================================
nano +67 ./inventory/mycluster/group_vars/k8s_cluster/k8s-cluster.yml

Enable Multus plugin (set to true)
===================================
nano +70 ./inventory/mycluster/group_vars/k8s_cluster/k8s-cluster.yml

ensure all nodes are accessible via SSH without password (example as below)
============================================================================================================
ssh-keygen -t rsa
ssh-copy-id -i /home/yockgenm/.ssh/id_rsa.pub yockgenm@192.168.0.17
ssh-copy-id -i /home/yockgenm/.ssh/id_rsa.pub yockgenm@192.168.0.18
ssh-copy-id -i /home/yockgenm/.ssh/id_rsa.pub yockgenm@192.168.0.19
ansible all -i inventory -m ping

*******************************************************************************************************************************************************************
Create k8s cluster
********************************************************************************************************************************************************************
ansible-playbook -i inventory/mycluster/hosts.yml --become --become-user=root cluster.yml -K 

To reset the cluster: 
ansible-playbook -i inventory/mycluster/hosts.yml --become --become-user=root reset.yml -K 



*******************************************************************************************************************************************************************
How to Test?
********************************************************************************************************************************************************************

create network definition - macvlan (option 1)
=============================================

cat <<EOF | kubectl create -f -
apiVersion: "k8s.cni.cncf.io/v1"
kind: NetworkAttachmentDefinition
metadata:
  name: yockgen-network
spec:
  config: '{
    "cniVersion": "0.3.1",
    "name": "yockgen-network",
    "type": "macvlan",
	"master": "ens8",
    "mode": "bridge",           
    "isDefaultGateway": false,
    "forceAddress": false,
    "ipMasq": false,
    "hairpinMode": false,
    "ipam": {
      "type": "host-local",
      "subnet": "192.168.1.0/24",
      "rangeStart": "192.168.1.201",
      "rangeEnd": "192.168.1.250",
      "routes": [
        { "dst": "0.0.0.0/0" }
      ],
      "gateway": "192.168.1.1"
    }
  }'
EOF

Important note, please make sure the master interface (here is "ens8") in all nodes are up properly and pingable between each others 

create network definition - OvS (option 2)
==========================================
1. Ensure all nodes with OvS bridge call "yockgen-br1" setup, simple OvS bridge could be as simple as below:
    
    ovs-vsctl add-br ovs-br1 -- set bridge ovs-br1 datapath_type=netdev
  
   This guide will not cover installation of OvS, please refer to official OvS web site

2.

cat <<EOF | kubectl create -f -
apiVersion: "k8s.cni.cncf.io/v1"
kind: NetworkAttachmentDefinition
metadata:
  name: yockgen-network
  annotations:
    k8s.v1.cni.cncf.io/resourceName: ovs-cni.network.kubevirt.io/br1
spec:
  config: '{
      "cniVersion": "0.3.0",
      "type": "ovs",
      "bridge": "ovs-br1",
      "vlan": 100,
	  "ipam": {
        "type": "whereabouts",
        "range": "192.168.2.225/28"
      }
    }'
EOF

Sample Deployment
=================
cat <<EOF | kubectl create -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: test01-deployment
  labels:
    app: yockgen
spec:
  replicas: 4
  selector:
    matchLabels:
      app: test01pod
  template:
    metadata:      
      annotations:
        k8s.v1.cni.cncf.io/networks: yockgen-network
      labels:
        app: test01pod
    spec:	
      containers:
      - name: test01pod
        command: ["/bin/ash", "-c", "trap : TERM INT; sleep infinity & wait"]
        image: alpine
        securityContext:
          capabilities:
            add: ["NET_ADMIN", "SYS_TIME","NET_RAW"]
EOF
